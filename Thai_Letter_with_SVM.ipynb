{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyN2PP/X9bxPHos8xfTeePqT",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/JustKeepPlay/PyProject/blob/main/Thai_Letter_with_SVM.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YIWR1Dj2CRXY",
        "outputId": "64688fe5-3d82-431b-e4df-acbf8b4c733d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: visualkeras in /usr/local/lib/python3.9/dist-packages (0.0.2)\n",
            "Requirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.9/dist-packages (from visualkeras) (8.4.0)\n",
            "Requirement already satisfied: numpy>=1.18.1 in /usr/local/lib/python3.9/dist-packages (from visualkeras) (1.22.4)\n",
            "Requirement already satisfied: aggdraw>=1.3.11 in /usr/local/lib/python3.9/dist-packages (from visualkeras) (1.3.16)\n"
          ]
        }
      ],
      "source": [
        "!pip install visualkeras\n",
        "\n",
        "\n",
        "import zipfile\n",
        "\n",
        "import os\n",
        "import warnings\n",
        "import itertools\n",
        "import cv2\n",
        "import seaborn as sns\n",
        "import pandas as pd\n",
        "import numpy  as np\n",
        "from PIL import Image\n",
        "from sklearn.utils import class_weight\n",
        "from collections import Counter\n",
        "from sklearn.preprocessing import scale\n",
        "import numpy as np\n",
        "from skimage.transform import resize\n",
        "from skimage.filters import gaussian\n",
        "from skimage.feature import canny\n",
        "from skimage.filters import threshold_otsu\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
        "import tensorflow as tf\n",
        "import visualkeras\n",
        "import matplotlib.pyplot as plt\n",
        "from tensorflow.keras.optimizers import SGD\n",
        "from tensorflow.python.keras.optimizer_v2.adam import Adam\n",
        "\n",
        "from tensorflow.keras.preprocessing.image import load_img\n",
        "from tensorflow.keras.utils import plot_model\n",
        "from tensorflow.keras.layers import Dense, BatchNormalization,LayerNormalization,UnitNormalization\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Conv2D, MaxPool2D, MaxPooling2D, GlobalAveragePooling2D, BatchNormalization, Dropout, Dense, Flatten, Input, Lambda\n",
        "from tensorflow.keras import layers\n",
        "from tensorflow.keras import regularizers\n",
        "from sklearn.model_selection   import train_test_split\n",
        "\n",
        "warnings.filterwarnings('ignore')\n",
        "%matplotlib inline"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive #case mounted gdrive\n",
        "drive.mount('/content/gdrive', force_remount=False)\n",
        "import os  #case connect via OS\n",
        "os.chdir(\"/content/gdrive/\")\n",
        "os.getcwd()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "id": "jfgZhujhGOWq",
        "outputId": "6390943c-5eaa-4bcf-8458-6df2f1c8263d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/gdrive; to attempt to forcibly remount, call drive.mount(\"/content/gdrive\", force_remount=True).\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'/content/gdrive'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 86
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "folder_path = \"/content/gdrive/MyDrive/Colab Notebooks/Pasa Thai\"\n",
        "bh_images = os.listdir(folder_path + '/bh/')\n",
        "#yes_images = os.listdir(folder_path + '/yes/')\n",
        "dataset=[]\n",
        "\n",
        "#categories = list(map(str,range(1,81)))\n",
        "categories = [i+1 for i in range(80)]\n",
        "\n",
        "\n",
        "for image_name in bh_images:\n",
        "    img=cv2.imread(folder_path + '/bh/' + image_name)\n",
        "\n",
        "    r, g, b = img[:,:,0], img[:,:,1], img[:,:,2]\n",
        "    gray = 0.2989 * r + 0.5870 * g + 0.1140 * b\n",
        "    gray_img = Image.fromarray(gray.astype('uint8'))\n",
        "\n",
        "\n",
        "\n",
        "    dataset.append(np.array(gray_img))\n",
        "\n",
        "    #lab.append(0)\n",
        "\n"
      ],
      "metadata": {
        "id": "TES3wwSkIYXH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dataset = np.asarray(dataset)\n",
        "dataset/255\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "It2rdXSZqwJE",
        "outputId": "04f753d3-4c52-4bb2-bb9d-c62ea57a3e92"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[[0.75294118, 0.74901961, 0.75294118, ..., 0.75294118,\n",
              "         0.72941176, 0.72941176],\n",
              "        [0.75294118, 0.74901961, 0.75294118, ..., 0.75294118,\n",
              "         0.7372549 , 0.7372549 ],\n",
              "        [0.75294118, 0.75294118, 0.75294118, ..., 0.74509804,\n",
              "         0.74117647, 0.74117647],\n",
              "        ...,\n",
              "        [0.72156863, 0.73333333, 0.72941176, ..., 0.7372549 ,\n",
              "         0.73333333, 0.73333333],\n",
              "        [0.7254902 , 0.7254902 , 0.7254902 , ..., 0.7372549 ,\n",
              "         0.72941176, 0.73333333],\n",
              "        [0.7254902 , 0.7254902 , 0.7254902 , ..., 0.74117647,\n",
              "         0.73333333, 0.73333333]],\n",
              "\n",
              "       [[0.77254902, 0.77647059, 0.78039216, ..., 0.76470588,\n",
              "         0.76078431, 0.76078431],\n",
              "        [0.76862745, 0.77254902, 0.78039216, ..., 0.76470588,\n",
              "         0.75686275, 0.75686275],\n",
              "        [0.77254902, 0.77254902, 0.77647059, ..., 0.76078431,\n",
              "         0.76862745, 0.76862745],\n",
              "        ...,\n",
              "        [0.75294118, 0.75294118, 0.75294118, ..., 0.76078431,\n",
              "         0.75294118, 0.75294118],\n",
              "        [0.74901961, 0.75686275, 0.76078431, ..., 0.76078431,\n",
              "         0.75294118, 0.75294118],\n",
              "        [0.75294118, 0.75686275, 0.76078431, ..., 0.75686275,\n",
              "         0.75294118, 0.75294118]],\n",
              "\n",
              "       [[0.74117647, 0.74117647, 0.74117647, ..., 0.74509804,\n",
              "         0.73333333, 0.74509804],\n",
              "        [0.7372549 , 0.74117647, 0.74117647, ..., 0.7372549 ,\n",
              "         0.74117647, 0.75294118],\n",
              "        [0.7372549 , 0.7372549 , 0.74117647, ..., 0.74509804,\n",
              "         0.74117647, 0.74901961],\n",
              "        ...,\n",
              "        [0.74509804, 0.73333333, 0.72941176, ..., 0.72941176,\n",
              "         0.71764706, 0.71764706],\n",
              "        [0.7372549 , 0.72941176, 0.73333333, ..., 0.74509804,\n",
              "         0.72941176, 0.71372549],\n",
              "        [0.74117647, 0.73333333, 0.73333333, ..., 0.7372549 ,\n",
              "         0.74901961, 0.73333333]],\n",
              "\n",
              "       ...,\n",
              "\n",
              "       [[0.61960784, 0.62352941, 0.62352941, ..., 0.62352941,\n",
              "         0.61960784, 0.61568627],\n",
              "        [0.59215686, 0.62352941, 0.62745098, ..., 0.61568627,\n",
              "         0.59607843, 0.59607843],\n",
              "        [0.62352941, 0.63921569, 0.62352941, ..., 0.60784314,\n",
              "         0.59215686, 0.59607843],\n",
              "        ...,\n",
              "        [0.5372549 , 0.52941176, 0.54117647, ..., 0.49411765,\n",
              "         0.47843137, 0.47843137],\n",
              "        [0.52156863, 0.53333333, 0.53333333, ..., 0.48627451,\n",
              "         0.49411765, 0.49411765],\n",
              "        [0.52156863, 0.53333333, 0.53333333, ..., 0.48627451,\n",
              "         0.49411765, 0.49411765]],\n",
              "\n",
              "       [[0.61176471, 0.60392157, 0.6       , ..., 0.60784314,\n",
              "         0.59607843, 0.6       ],\n",
              "        [0.60784314, 0.59607843, 0.58823529, ..., 0.60392157,\n",
              "         0.61176471, 0.61176471],\n",
              "        [0.60784314, 0.59215686, 0.58431373, ..., 0.6       ,\n",
              "         0.57647059, 0.58039216],\n",
              "        ...,\n",
              "        [0.51764706, 0.5254902 , 0.51372549, ..., 0.54117647,\n",
              "         0.52156863, 0.5254902 ],\n",
              "        [0.52941176, 0.52156863, 0.52941176, ..., 0.52941176,\n",
              "         0.5372549 , 0.52156863],\n",
              "        [0.5372549 , 0.52156863, 0.52156863, ..., 0.5254902 ,\n",
              "         0.54117647, 0.52156863]],\n",
              "\n",
              "       [[0.69411765, 0.69803922, 0.70588235, ..., 0.71764706,\n",
              "         0.72941176, 0.7254902 ],\n",
              "        [0.70196078, 0.70588235, 0.70980392, ..., 0.7254902 ,\n",
              "         0.71764706, 0.71764706],\n",
              "        [0.70196078, 0.70588235, 0.70980392, ..., 0.73333333,\n",
              "         0.71764706, 0.71764706],\n",
              "        ...,\n",
              "        [0.6627451 , 0.67058824, 0.67843137, ..., 0.69411765,\n",
              "         0.69019608, 0.69019608],\n",
              "        [0.66666667, 0.68627451, 0.66666667, ..., 0.68627451,\n",
              "         0.69803922, 0.69803922],\n",
              "        [0.67058824, 0.68627451, 0.66666667, ..., 0.68627451,\n",
              "         0.69803922, 0.69803922]]])"
            ]
          },
          "metadata": {},
          "execution_count": 115
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "dataset = dataset.reshape(-1,90,90,1)\n",
        "dataset.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "x_xcLZL1sdlw",
        "outputId": "3d08a033-dc57-48b7-e2cf-5d63a6b236be"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(80, 90, 90, 1)"
            ]
          },
          "metadata": {},
          "execution_count": 116
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "categories =np.asarray(categories)\n",
        "categories.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2SXHOUSVlryF",
        "outputId": "f878c606-df8d-454a-d680-e026d63fb6ad"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(80,)"
            ]
          },
          "metadata": {},
          "execution_count": 117
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from keras.utils.np_utils import to_categorical\n",
        "categories = to_categorical(categories)"
      ],
      "metadata": {
        "id": "rFz9aVvSsvJN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "categories"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f5iGccy574Rn",
        "outputId": "d564c009-423b-45e1-d88c-7220f4816bf0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0., 1., 0., ..., 0., 0., 0.],\n",
              "       [0., 0., 1., ..., 0., 0., 0.],\n",
              "       [0., 0., 0., ..., 0., 0., 0.],\n",
              "       ...,\n",
              "       [0., 0., 0., ..., 1., 0., 0.],\n",
              "       [0., 0., 0., ..., 0., 1., 0.],\n",
              "       [0., 0., 0., ..., 0., 0., 1.]], dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 119
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras import regularizers\n",
        "model = Sequential()\n",
        "model.add(Conv2D(filters=32,kernel_size=(3,3),strides=(2,2), activation=\"relu\", padding=\"valid\",input_shape=(90,90,1)))\n",
        "model.add(MaxPooling2D((2, 2)))\n",
        "#model.add(BatchNormalization())\n",
        "#model.add(LayerNormalization())\n",
        "\n",
        "model.add(Conv2D(filters=32,kernel_size=(3,3),strides=(2,2), activation=\"relu\", padding=\"valid\"))\n",
        "model.add(MaxPooling2D((2, 2)))\n",
        "\n",
        "#model.add(BatchNormalization())\n",
        "model.add(Flatten())\n",
        "\n",
        "model.add(Dense(units=80, activation='relu'))\n",
        "    # kernel_regularizer=regularizers.L1L2(l1=1e-5, l2=1e-4),\n",
        "    # bias_regularizer=regularizers.L2(1e-4),\n",
        "    # activity_regularizer=regularizers.L2(1e-5)\n",
        "\n",
        "#Regularizers is an optimization to give penalty to neuron per-layer **in this case I used it instead of Dropout\n",
        "\n",
        "model.add(Dropout(0.3))\n",
        "model.add(Dense(81, activation='softmax'))"
      ],
      "metadata": {
        "id": "bvtPuERityPc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "optimizer = tf.keras.optimizers.RMSprop(lr=0.001, rho=0.9, epsilon=1e-08)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TuBvFO_buTN_",
        "outputId": "55c7736b-b583-4b46-93d9-7b214ef421c4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:`lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.RMSprop.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X_train, X_val, Y_train, Y_val = train_test_split(dataset, categories, test_size = 0.2,shuffle=True, random_state=42)"
      ],
      "metadata": {
        "id": "IbrkU8Esujnv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(X_train.shape)\n",
        "print(X_val.shape)\n",
        "print(Y_train.shape)\n",
        "print(Y_val.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3ullfDxJ7cwO",
        "outputId": "00103b42-569a-4976-b86c-474c2e02e5f3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(64, 90, 90, 1)\n",
            "(16, 90, 90, 1)\n",
            "(64, 81)\n",
            "(16, 81)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# from keras.preprocessing.image import ImageDataGenerator\n",
        "# datagen = ImageDataGenerator(\n",
        "#         featurewise_center=False,  # set input mean to 0 over the dataset\n",
        "#         samplewise_center=False,  # set each sample mean to 0\n",
        "#         featurewise_std_normalization=False,  # divide inputs by std of the dataset\n",
        "#         samplewise_std_normalization=False,  # divide each input by its std\n",
        "#         zca_whitening=False,  # apply ZCA whitening\n",
        "#         rotation_range=10,  # randomly rotate images in the range (degrees, 0 to 180)\n",
        "#         zoom_range = 0.1, # Randomly zoom image\n",
        "#         width_shift_range=0.1,  # randomly shift images horizontally (fraction of total width)\n",
        "#         height_shift_range=0.1,  # randomly shift images vertically (fraction of total height)\n",
        "#         horizontal_flip=False,  # randomly flip images\n",
        "#         vertical_flip=False)  # randomly flip images\n",
        "\n",
        "\n",
        "# datagen.fit(X_train)"
      ],
      "metadata": {
        "id": "oEsgD9Wou6Lk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "opt = Adam(learning_rate=1e-3)\n",
        "model.compile(optimizer = \"adam\", loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "39mgcWVIvHPj",
        "outputId": "f0a83d5f-c2e4-4610-82ea-2f62e0a9e8b9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_10\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv2d_24 (Conv2D)          (None, 44, 44, 32)        320       \n",
            "                                                                 \n",
            " max_pooling2d_20 (MaxPoolin  (None, 22, 22, 32)       0         \n",
            " g2D)                                                            \n",
            "                                                                 \n",
            " conv2d_25 (Conv2D)          (None, 10, 10, 32)        9248      \n",
            "                                                                 \n",
            " max_pooling2d_21 (MaxPoolin  (None, 5, 5, 32)         0         \n",
            " g2D)                                                            \n",
            "                                                                 \n",
            " flatten_10 (Flatten)        (None, 800)               0         \n",
            "                                                                 \n",
            " dense_21 (Dense)            (None, 80)                64080     \n",
            "                                                                 \n",
            " dropout_14 (Dropout)        (None, 80)                0         \n",
            "                                                                 \n",
            " dense_22 (Dense)            (None, 81)                6561      \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 80,209\n",
            "Trainable params: 80,209\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "history = model.fit(X_train,Y_train,batch_size=32 ,epochs = 100, validation_data=(X_val, Y_val),verbose=1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lHhepM0AvWUT",
        "outputId": "6ba4bdc9-2008-4337-b77a-5af6308e0c1b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "2/2 [==============================] - 2s 414ms/step - loss: 60.2951 - accuracy: 0.0000e+00 - val_loss: 29.6594 - val_accuracy: 0.0000e+00\n",
            "Epoch 2/100\n",
            "2/2 [==============================] - 0s 136ms/step - loss: 25.5354 - accuracy: 0.0156 - val_loss: 13.6243 - val_accuracy: 0.0000e+00\n",
            "Epoch 3/100\n",
            "2/2 [==============================] - 0s 137ms/step - loss: 10.0721 - accuracy: 0.0312 - val_loss: 5.7053 - val_accuracy: 0.0000e+00\n",
            "Epoch 4/100\n",
            "2/2 [==============================] - 0s 133ms/step - loss: 4.7552 - accuracy: 0.0000e+00 - val_loss: 4.5544 - val_accuracy: 0.0625\n",
            "Epoch 5/100\n",
            "2/2 [==============================] - 0s 134ms/step - loss: 4.5844 - accuracy: 0.0156 - val_loss: 4.8625 - val_accuracy: 0.0625\n",
            "Epoch 6/100\n",
            "2/2 [==============================] - 0s 136ms/step - loss: 4.4455 - accuracy: 0.0000e+00 - val_loss: 4.6928 - val_accuracy: 0.0000e+00\n",
            "Epoch 7/100\n",
            "2/2 [==============================] - 0s 140ms/step - loss: 4.2977 - accuracy: 0.0000e+00 - val_loss: 4.5961 - val_accuracy: 0.0000e+00\n",
            "Epoch 8/100\n",
            "2/2 [==============================] - 0s 90ms/step - loss: 4.3461 - accuracy: 0.0156 - val_loss: 4.5646 - val_accuracy: 0.0000e+00\n",
            "Epoch 9/100\n",
            "2/2 [==============================] - 0s 76ms/step - loss: 4.3373 - accuracy: 0.0156 - val_loss: 4.6196 - val_accuracy: 0.0000e+00\n",
            "Epoch 10/100\n",
            "2/2 [==============================] - 0s 90ms/step - loss: 4.3564 - accuracy: 0.0469 - val_loss: 4.7189 - val_accuracy: 0.0000e+00\n",
            "Epoch 11/100\n",
            "2/2 [==============================] - 0s 78ms/step - loss: 4.4176 - accuracy: 0.0312 - val_loss: 4.6377 - val_accuracy: 0.0000e+00\n",
            "Epoch 12/100\n",
            "2/2 [==============================] - 0s 91ms/step - loss: 4.2926 - accuracy: 0.0312 - val_loss: 4.5134 - val_accuracy: 0.0000e+00\n",
            "Epoch 13/100\n",
            "2/2 [==============================] - 0s 79ms/step - loss: 4.3369 - accuracy: 0.0156 - val_loss: 4.5188 - val_accuracy: 0.0000e+00\n",
            "Epoch 14/100\n",
            "2/2 [==============================] - 0s 77ms/step - loss: 4.3599 - accuracy: 0.0156 - val_loss: 4.5438 - val_accuracy: 0.0000e+00\n",
            "Epoch 15/100\n",
            "2/2 [==============================] - 0s 118ms/step - loss: 4.2853 - accuracy: 0.0312 - val_loss: 4.6147 - val_accuracy: 0.0000e+00\n",
            "Epoch 16/100\n",
            "2/2 [==============================] - 0s 90ms/step - loss: 4.3230 - accuracy: 0.0312 - val_loss: 4.5584 - val_accuracy: 0.0000e+00\n",
            "Epoch 17/100\n",
            "2/2 [==============================] - 0s 91ms/step - loss: 4.2267 - accuracy: 0.0469 - val_loss: 4.6815 - val_accuracy: 0.0000e+00\n",
            "Epoch 18/100\n",
            "2/2 [==============================] - 0s 78ms/step - loss: 4.3330 - accuracy: 0.0156 - val_loss: 4.6472 - val_accuracy: 0.0000e+00\n",
            "Epoch 19/100\n",
            "2/2 [==============================] - 0s 93ms/step - loss: 4.2446 - accuracy: 0.0312 - val_loss: 4.5927 - val_accuracy: 0.0000e+00\n",
            "Epoch 20/100\n",
            "2/2 [==============================] - 0s 89ms/step - loss: 4.2293 - accuracy: 0.0312 - val_loss: 4.6625 - val_accuracy: 0.0000e+00\n",
            "Epoch 21/100\n",
            "2/2 [==============================] - 0s 289ms/step - loss: 4.2019 - accuracy: 0.0469 - val_loss: 4.7501 - val_accuracy: 0.0000e+00\n",
            "Epoch 22/100\n",
            "2/2 [==============================] - 0s 274ms/step - loss: 4.2377 - accuracy: 0.0156 - val_loss: 4.8694 - val_accuracy: 0.0625\n",
            "Epoch 23/100\n",
            "2/2 [==============================] - 0s 120ms/step - loss: 4.1854 - accuracy: 0.0156 - val_loss: 4.8510 - val_accuracy: 0.0625\n",
            "Epoch 24/100\n",
            "2/2 [==============================] - 0s 75ms/step - loss: 4.1382 - accuracy: 0.0312 - val_loss: 4.8629 - val_accuracy: 0.0000e+00\n",
            "Epoch 25/100\n",
            "2/2 [==============================] - 0s 92ms/step - loss: 4.1672 - accuracy: 0.0312 - val_loss: 4.7480 - val_accuracy: 0.0000e+00\n",
            "Epoch 26/100\n",
            "2/2 [==============================] - 0s 75ms/step - loss: 4.1049 - accuracy: 0.0625 - val_loss: 4.7613 - val_accuracy: 0.0000e+00\n",
            "Epoch 27/100\n",
            "2/2 [==============================] - 0s 77ms/step - loss: 4.0864 - accuracy: 0.0312 - val_loss: 4.8661 - val_accuracy: 0.0000e+00\n",
            "Epoch 28/100\n",
            "2/2 [==============================] - 0s 94ms/step - loss: 4.0212 - accuracy: 0.0469 - val_loss: 5.1408 - val_accuracy: 0.0000e+00\n",
            "Epoch 29/100\n",
            "2/2 [==============================] - 0s 76ms/step - loss: 4.1157 - accuracy: 0.0469 - val_loss: 4.8197 - val_accuracy: 0.0000e+00\n",
            "Epoch 30/100\n",
            "2/2 [==============================] - 0s 76ms/step - loss: 4.1651 - accuracy: 0.0312 - val_loss: 4.8809 - val_accuracy: 0.0000e+00\n",
            "Epoch 31/100\n",
            "2/2 [==============================] - 0s 90ms/step - loss: 3.9991 - accuracy: 0.0469 - val_loss: 5.1309 - val_accuracy: 0.0000e+00\n",
            "Epoch 32/100\n",
            "2/2 [==============================] - 0s 90ms/step - loss: 3.9980 - accuracy: 0.0469 - val_loss: 5.1488 - val_accuracy: 0.0000e+00\n",
            "Epoch 33/100\n",
            "2/2 [==============================] - 0s 78ms/step - loss: 3.9228 - accuracy: 0.0469 - val_loss: 4.9708 - val_accuracy: 0.0000e+00\n",
            "Epoch 34/100\n",
            "2/2 [==============================] - 0s 78ms/step - loss: 3.8630 - accuracy: 0.0781 - val_loss: 5.0234 - val_accuracy: 0.0000e+00\n",
            "Epoch 35/100\n",
            "2/2 [==============================] - 0s 95ms/step - loss: 3.9763 - accuracy: 0.0469 - val_loss: 5.1064 - val_accuracy: 0.0000e+00\n",
            "Epoch 36/100\n",
            "2/2 [==============================] - 0s 84ms/step - loss: 3.8964 - accuracy: 0.0781 - val_loss: 5.0322 - val_accuracy: 0.0000e+00\n",
            "Epoch 37/100\n",
            "2/2 [==============================] - 0s 97ms/step - loss: 3.7253 - accuracy: 0.0938 - val_loss: 5.0088 - val_accuracy: 0.0000e+00\n",
            "Epoch 38/100\n",
            "2/2 [==============================] - 0s 90ms/step - loss: 3.9663 - accuracy: 0.0312 - val_loss: 5.1251 - val_accuracy: 0.0000e+00\n",
            "Epoch 39/100\n",
            "2/2 [==============================] - 0s 105ms/step - loss: 3.8118 - accuracy: 0.0625 - val_loss: 5.2072 - val_accuracy: 0.0000e+00\n",
            "Epoch 40/100\n",
            "2/2 [==============================] - 0s 91ms/step - loss: 3.7647 - accuracy: 0.1250 - val_loss: 5.1132 - val_accuracy: 0.0000e+00\n",
            "Epoch 41/100\n",
            "2/2 [==============================] - 0s 77ms/step - loss: 3.5329 - accuracy: 0.0938 - val_loss: 5.2965 - val_accuracy: 0.0000e+00\n",
            "Epoch 42/100\n",
            "2/2 [==============================] - 0s 89ms/step - loss: 3.6714 - accuracy: 0.0625 - val_loss: 5.0531 - val_accuracy: 0.0000e+00\n",
            "Epoch 43/100\n",
            "2/2 [==============================] - 0s 78ms/step - loss: 3.6643 - accuracy: 0.0938 - val_loss: 5.2318 - val_accuracy: 0.0000e+00\n",
            "Epoch 44/100\n",
            "2/2 [==============================] - 0s 84ms/step - loss: 3.5885 - accuracy: 0.1250 - val_loss: 5.4324 - val_accuracy: 0.0000e+00\n",
            "Epoch 45/100\n",
            "2/2 [==============================] - 0s 90ms/step - loss: 3.6548 - accuracy: 0.0938 - val_loss: 5.2931 - val_accuracy: 0.0000e+00\n",
            "Epoch 46/100\n",
            "2/2 [==============================] - 0s 77ms/step - loss: 3.6072 - accuracy: 0.0625 - val_loss: 5.2839 - val_accuracy: 0.0000e+00\n",
            "Epoch 47/100\n",
            "2/2 [==============================] - 0s 91ms/step - loss: 3.5922 - accuracy: 0.0781 - val_loss: 5.4217 - val_accuracy: 0.0000e+00\n",
            "Epoch 48/100\n",
            "2/2 [==============================] - 0s 89ms/step - loss: 3.5573 - accuracy: 0.0938 - val_loss: 5.4944 - val_accuracy: 0.0000e+00\n",
            "Epoch 49/100\n",
            "2/2 [==============================] - 0s 79ms/step - loss: 3.4516 - accuracy: 0.1250 - val_loss: 5.5675 - val_accuracy: 0.0000e+00\n",
            "Epoch 50/100\n",
            "2/2 [==============================] - 0s 78ms/step - loss: 3.3795 - accuracy: 0.1406 - val_loss: 5.5495 - val_accuracy: 0.0000e+00\n",
            "Epoch 51/100\n",
            "2/2 [==============================] - 0s 89ms/step - loss: 3.4748 - accuracy: 0.0312 - val_loss: 5.6032 - val_accuracy: 0.0000e+00\n",
            "Epoch 52/100\n",
            "2/2 [==============================] - 0s 85ms/step - loss: 3.5361 - accuracy: 0.0938 - val_loss: 5.5216 - val_accuracy: 0.0000e+00\n",
            "Epoch 53/100\n",
            "2/2 [==============================] - 0s 86ms/step - loss: 3.3077 - accuracy: 0.1250 - val_loss: 5.5823 - val_accuracy: 0.0000e+00\n",
            "Epoch 54/100\n",
            "2/2 [==============================] - 0s 78ms/step - loss: 3.4959 - accuracy: 0.0938 - val_loss: 5.7771 - val_accuracy: 0.0000e+00\n",
            "Epoch 55/100\n",
            "2/2 [==============================] - 0s 95ms/step - loss: 3.5370 - accuracy: 0.0781 - val_loss: 5.8438 - val_accuracy: 0.0000e+00\n",
            "Epoch 56/100\n",
            "2/2 [==============================] - 0s 77ms/step - loss: 3.5622 - accuracy: 0.0938 - val_loss: 5.4837 - val_accuracy: 0.0000e+00\n",
            "Epoch 57/100\n",
            "2/2 [==============================] - 0s 89ms/step - loss: 3.5402 - accuracy: 0.0781 - val_loss: 5.5088 - val_accuracy: 0.0000e+00\n",
            "Epoch 58/100\n",
            "2/2 [==============================] - 0s 94ms/step - loss: 3.2506 - accuracy: 0.1875 - val_loss: 6.3430 - val_accuracy: 0.0000e+00\n",
            "Epoch 59/100\n",
            "2/2 [==============================] - 0s 75ms/step - loss: 3.4410 - accuracy: 0.0938 - val_loss: 6.2059 - val_accuracy: 0.0000e+00\n",
            "Epoch 60/100\n",
            "2/2 [==============================] - 0s 88ms/step - loss: 3.2587 - accuracy: 0.0625 - val_loss: 5.7733 - val_accuracy: 0.0000e+00\n",
            "Epoch 61/100\n",
            "2/2 [==============================] - 0s 88ms/step - loss: 3.1503 - accuracy: 0.1562 - val_loss: 5.7379 - val_accuracy: 0.0000e+00\n",
            "Epoch 62/100\n",
            "2/2 [==============================] - 0s 88ms/step - loss: 3.2313 - accuracy: 0.1406 - val_loss: 6.3259 - val_accuracy: 0.0000e+00\n",
            "Epoch 63/100\n",
            "2/2 [==============================] - 0s 82ms/step - loss: 3.2185 - accuracy: 0.1562 - val_loss: 6.3463 - val_accuracy: 0.0000e+00\n",
            "Epoch 64/100\n",
            "2/2 [==============================] - 0s 78ms/step - loss: 3.5259 - accuracy: 0.0781 - val_loss: 5.8636 - val_accuracy: 0.0000e+00\n",
            "Epoch 65/100\n",
            "2/2 [==============================] - 0s 78ms/step - loss: 3.1743 - accuracy: 0.1719 - val_loss: 5.9904 - val_accuracy: 0.0000e+00\n",
            "Epoch 66/100\n",
            "2/2 [==============================] - 0s 76ms/step - loss: 3.3979 - accuracy: 0.0938 - val_loss: 6.5433 - val_accuracy: 0.0000e+00\n",
            "Epoch 67/100\n",
            "2/2 [==============================] - 0s 78ms/step - loss: 3.1678 - accuracy: 0.1406 - val_loss: 6.4341 - val_accuracy: 0.0000e+00\n",
            "Epoch 68/100\n",
            "2/2 [==============================] - 0s 78ms/step - loss: 3.2403 - accuracy: 0.1406 - val_loss: 6.0241 - val_accuracy: 0.0000e+00\n",
            "Epoch 69/100\n",
            "2/2 [==============================] - 0s 81ms/step - loss: 3.0936 - accuracy: 0.1719 - val_loss: 6.2173 - val_accuracy: 0.0000e+00\n",
            "Epoch 70/100\n",
            "2/2 [==============================] - 0s 89ms/step - loss: 3.3561 - accuracy: 0.0938 - val_loss: 6.5237 - val_accuracy: 0.0000e+00\n",
            "Epoch 71/100\n",
            "2/2 [==============================] - 0s 85ms/step - loss: 3.0386 - accuracy: 0.1719 - val_loss: 6.4609 - val_accuracy: 0.0000e+00\n",
            "Epoch 72/100\n",
            "2/2 [==============================] - 0s 79ms/step - loss: 2.8638 - accuracy: 0.2188 - val_loss: 6.6132 - val_accuracy: 0.0000e+00\n",
            "Epoch 73/100\n",
            "2/2 [==============================] - 0s 80ms/step - loss: 2.9726 - accuracy: 0.2188 - val_loss: 6.5816 - val_accuracy: 0.0000e+00\n",
            "Epoch 74/100\n",
            "2/2 [==============================] - 0s 81ms/step - loss: 3.0260 - accuracy: 0.1719 - val_loss: 6.7342 - val_accuracy: 0.0000e+00\n",
            "Epoch 75/100\n",
            "2/2 [==============================] - 0s 76ms/step - loss: 2.9288 - accuracy: 0.2344 - val_loss: 6.8490 - val_accuracy: 0.0000e+00\n",
            "Epoch 76/100\n",
            "2/2 [==============================] - 0s 88ms/step - loss: 2.8642 - accuracy: 0.1719 - val_loss: 6.7170 - val_accuracy: 0.0000e+00\n",
            "Epoch 77/100\n",
            "2/2 [==============================] - 0s 144ms/step - loss: 3.1034 - accuracy: 0.1875 - val_loss: 6.7366 - val_accuracy: 0.0000e+00\n",
            "Epoch 78/100\n",
            "2/2 [==============================] - 0s 129ms/step - loss: 3.0075 - accuracy: 0.1562 - val_loss: 6.6947 - val_accuracy: 0.0000e+00\n",
            "Epoch 79/100\n",
            "2/2 [==============================] - 0s 134ms/step - loss: 2.8813 - accuracy: 0.1562 - val_loss: 7.0238 - val_accuracy: 0.0000e+00\n",
            "Epoch 80/100\n",
            "2/2 [==============================] - 0s 136ms/step - loss: 2.8410 - accuracy: 0.2031 - val_loss: 7.0661 - val_accuracy: 0.0000e+00\n",
            "Epoch 81/100\n",
            "2/2 [==============================] - 0s 151ms/step - loss: 2.8278 - accuracy: 0.2031 - val_loss: 6.7156 - val_accuracy: 0.0000e+00\n",
            "Epoch 82/100\n",
            "2/2 [==============================] - 0s 140ms/step - loss: 2.8903 - accuracy: 0.2188 - val_loss: 6.6513 - val_accuracy: 0.0000e+00\n",
            "Epoch 83/100\n",
            "2/2 [==============================] - 0s 147ms/step - loss: 3.0462 - accuracy: 0.1094 - val_loss: 6.9156 - val_accuracy: 0.0000e+00\n",
            "Epoch 84/100\n",
            "2/2 [==============================] - 0s 164ms/step - loss: 3.0170 - accuracy: 0.1719 - val_loss: 7.3751 - val_accuracy: 0.0000e+00\n",
            "Epoch 85/100\n",
            "2/2 [==============================] - 0s 148ms/step - loss: 2.7932 - accuracy: 0.2656 - val_loss: 7.3969 - val_accuracy: 0.0000e+00\n",
            "Epoch 86/100\n",
            "2/2 [==============================] - 0s 144ms/step - loss: 2.9591 - accuracy: 0.1875 - val_loss: 6.7270 - val_accuracy: 0.0000e+00\n",
            "Epoch 87/100\n",
            "2/2 [==============================] - 0s 144ms/step - loss: 2.8935 - accuracy: 0.1875 - val_loss: 6.5613 - val_accuracy: 0.0000e+00\n",
            "Epoch 88/100\n",
            "2/2 [==============================] - 0s 141ms/step - loss: 2.7147 - accuracy: 0.2656 - val_loss: 7.4422 - val_accuracy: 0.0000e+00\n",
            "Epoch 89/100\n",
            "2/2 [==============================] - 0s 125ms/step - loss: 3.0243 - accuracy: 0.1250 - val_loss: 7.6319 - val_accuracy: 0.0000e+00\n",
            "Epoch 90/100\n",
            "2/2 [==============================] - 0s 132ms/step - loss: 2.7073 - accuracy: 0.2188 - val_loss: 7.0681 - val_accuracy: 0.0000e+00\n",
            "Epoch 91/100\n",
            "2/2 [==============================] - 0s 152ms/step - loss: 2.8974 - accuracy: 0.1719 - val_loss: 6.9533 - val_accuracy: 0.0000e+00\n",
            "Epoch 92/100\n",
            "2/2 [==============================] - 0s 139ms/step - loss: 2.6191 - accuracy: 0.2656 - val_loss: 7.5410 - val_accuracy: 0.0000e+00\n",
            "Epoch 93/100\n",
            "2/2 [==============================] - 0s 129ms/step - loss: 2.7376 - accuracy: 0.2344 - val_loss: 7.9868 - val_accuracy: 0.0000e+00\n",
            "Epoch 94/100\n",
            "2/2 [==============================] - 0s 132ms/step - loss: 2.7103 - accuracy: 0.2031 - val_loss: 7.8714 - val_accuracy: 0.0000e+00\n",
            "Epoch 95/100\n",
            "2/2 [==============================] - 0s 148ms/step - loss: 2.7294 - accuracy: 0.2812 - val_loss: 7.5567 - val_accuracy: 0.0000e+00\n",
            "Epoch 96/100\n",
            "2/2 [==============================] - 0s 133ms/step - loss: 2.8004 - accuracy: 0.2500 - val_loss: 7.4968 - val_accuracy: 0.0000e+00\n",
            "Epoch 97/100\n",
            "2/2 [==============================] - 0s 138ms/step - loss: 2.9042 - accuracy: 0.1875 - val_loss: 7.4503 - val_accuracy: 0.0000e+00\n",
            "Epoch 98/100\n",
            "2/2 [==============================] - 0s 119ms/step - loss: 2.6995 - accuracy: 0.2188 - val_loss: 7.6582 - val_accuracy: 0.0000e+00\n",
            "Epoch 99/100\n",
            "2/2 [==============================] - 0s 96ms/step - loss: 2.5585 - accuracy: 0.2969 - val_loss: 8.1650 - val_accuracy: 0.0000e+00\n",
            "Epoch 100/100\n",
            "2/2 [==============================] - 0s 87ms/step - loss: 2.6934 - accuracy: 0.2188 - val_loss: 8.3507 - val_accuracy: 0.0000e+00\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "g = plt.imshow(X_train[8][:,:,0])"
      ],
      "metadata": {
        "id": "jJRLW3204kLL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn import svm\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score\n",
        "clf = svm.SVC(kernel='linear')\n",
        "\n",
        "# Train the classifier on the training set\n",
        "clf.fit(X_t, Y_train)\n",
        "\n",
        "# Use the classifier to predict labels for the testing set\n",
        "y_pred = clf.predict(X_val)\n",
        "\n",
        "# Compute the accuracy of the classifier\n",
        "acc = accuracy_score(Y_val, y_pred)\n",
        "\n",
        "print(\"Accuracy: {:.2f}%\".format(acc*100))"
      ],
      "metadata": {
        "id": "Z792ufU9wsdL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "wISMnaXsyWjH"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}